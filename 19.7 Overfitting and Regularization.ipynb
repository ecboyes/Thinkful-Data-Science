{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load the houseprices data from Thinkful's database.\n",
    "- Reimplement your model from the previous checkpoint.\n",
    "- Try OLS, Lasso, Ridge, and ElasticNet regression using the same model specification. This time, you need to do k-fold cross-validation to choose the best hyperparameter values for your models. Which model is the best? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from statsmodels.tools.eval_measures import mse, rmse\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Display preferences.\n",
    "%matplotlib inline\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "postgres_user = 'dsbc_student'\n",
    "postgres_pw = '7*.8G9QH21'\n",
    "postgres_host = '142.93.121.174'\n",
    "postgres_port = '5432'\n",
    "postgres_db = 'houseprices'\n",
    "\n",
    "engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(\n",
    "    postgres_user, postgres_pw, postgres_host, postgres_port, postgres_db))\n",
    "house_df = pd.read_sql_query('select * from houseprices',con=engine)\n",
    "\n",
    "# no need for an open connection, as we're only doing a single query\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_df = pd.concat([house_df,pd.get_dummies(house_df.mszoning, prefix=\"mszoning\", drop_first=True)], axis=1)\n",
    "house_df = pd.concat([house_df,pd.get_dummies(house_df.street, prefix=\"street\", drop_first=True)], axis=1)\n",
    "dummy_column_names = list(pd.get_dummies(house_df.mszoning, prefix=\"mszoning\", drop_first=True).columns)\n",
    "dummy_column_names = dummy_column_names + list(pd.get_dummies(house_df.street, prefix=\"street\", drop_first=True).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>saleprice</td>    <th>  R-squared:         </th> <td>   0.832</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.831</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   520.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 06 Aug 2019</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:28:14</td>     <th>  Log-Likelihood:    </th> <td>  463.99</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th> <td>  -904.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1156</td>      <th>  BIC:               </th> <td>  -843.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    11</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                  <td></td>                     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                             <td>    9.9162</td> <td>    0.102</td> <td>   97.518</td> <td> 0.000</td> <td>    9.717</td> <td>   10.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>overallqual</th>                       <td>    0.1893</td> <td>    0.009</td> <td>   20.123</td> <td> 0.000</td> <td>    0.171</td> <td>    0.208</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grlivarea</th>                         <td>  9.58e-05</td> <td> 1.89e-05</td> <td>    5.074</td> <td> 0.000</td> <td> 5.88e-05</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>garagecars</th>                        <td>    0.0779</td> <td>    0.015</td> <td>    5.244</td> <td> 0.000</td> <td>    0.049</td> <td>    0.107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>garagearea</th>                        <td>    0.0001</td> <td> 5.04e-05</td> <td>    2.132</td> <td> 0.033</td> <td> 8.57e-06</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>totalsqft</th>                         <td>    0.0003</td> <td> 2.58e-05</td> <td>   11.139</td> <td> 0.000</td> <td>    0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>totalsqft_overallqual_interaction</th> <td>-2.572e-05</td> <td> 3.02e-06</td> <td>   -8.526</td> <td> 0.000</td> <td>-3.16e-05</td> <td>-1.98e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mszoning_FV</th>                       <td>    0.3911</td> <td>    0.065</td> <td>    6.055</td> <td> 0.000</td> <td>    0.264</td> <td>    0.518</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mszoning_RH</th>                       <td>    0.2650</td> <td>    0.074</td> <td>    3.593</td> <td> 0.000</td> <td>    0.120</td> <td>    0.410</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mszoning_RL</th>                       <td>    0.3879</td> <td>    0.060</td> <td>    6.481</td> <td> 0.000</td> <td>    0.270</td> <td>    0.505</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mszoning_RM</th>                       <td>    0.2155</td> <td>    0.061</td> <td>    3.556</td> <td> 0.000</td> <td>    0.097</td> <td>    0.334</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>street_Pave</th>                       <td>   -0.0556</td> <td>    0.075</td> <td>   -0.744</td> <td> 0.457</td> <td>   -0.202</td> <td>    0.091</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>350.711</td> <th>  Durbin-Watson:     </th> <td>   1.876</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2714.386</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-1.167</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>10.094</td>  <th>  Cond. No.          </th> <td>5.33e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 5.33e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              saleprice   R-squared:                       0.832\n",
       "Model:                            OLS   Adj. R-squared:                  0.831\n",
       "Method:                 Least Squares   F-statistic:                     520.9\n",
       "Date:                Tue, 06 Aug 2019   Prob (F-statistic):               0.00\n",
       "Time:                        19:28:14   Log-Likelihood:                 463.99\n",
       "No. Observations:                1168   AIC:                            -904.0\n",
       "Df Residuals:                    1156   BIC:                            -843.2\n",
       "Df Model:                          11                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=====================================================================================================\n",
       "                                        coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------------------\n",
       "const                                 9.9162      0.102     97.518      0.000       9.717      10.116\n",
       "overallqual                           0.1893      0.009     20.123      0.000       0.171       0.208\n",
       "grlivarea                           9.58e-05   1.89e-05      5.074      0.000    5.88e-05       0.000\n",
       "garagecars                            0.0779      0.015      5.244      0.000       0.049       0.107\n",
       "garagearea                            0.0001   5.04e-05      2.132      0.033    8.57e-06       0.000\n",
       "totalsqft                             0.0003   2.58e-05     11.139      0.000       0.000       0.000\n",
       "totalsqft_overallqual_interaction -2.572e-05   3.02e-06     -8.526      0.000   -3.16e-05   -1.98e-05\n",
       "mszoning_FV                           0.3911      0.065      6.055      0.000       0.264       0.518\n",
       "mszoning_RH                           0.2650      0.074      3.593      0.000       0.120       0.410\n",
       "mszoning_RL                           0.3879      0.060      6.481      0.000       0.270       0.505\n",
       "mszoning_RM                           0.2155      0.061      3.556      0.000       0.097       0.334\n",
       "street_Pave                          -0.0556      0.075     -0.744      0.457      -0.202       0.091\n",
       "==============================================================================\n",
       "Omnibus:                      350.711   Durbin-Watson:                   1.876\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2714.386\n",
       "Skew:                          -1.167   Prob(JB):                         0.00\n",
       "Kurtosis:                      10.094   Cond. No.                     5.33e+05\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 5.33e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_df['totalsqft'] = house_df['totalbsmtsf'] + house_df['firstflrsf'] + house_df['secondflrsf']\n",
    "\n",
    "house_df['totalsqft_overallqual_interaction'] = house_df['totalsqft'] * house_df['overallqual']\n",
    "\n",
    "# Y is the target variable\n",
    "Y = np.log1p(house_df['saleprice'])\n",
    "# X is the feature set\n",
    "X = house_df[['overallqual', 'grlivarea', 'garagecars', 'garagearea', 'totalsqft', 'totalsqft_overallqual_interaction'] + dummy_column_names]\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 465)\n",
    "\n",
    "results = sm.OLS(y_train, X_train).fit()\n",
    "\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared of the model in the training set is: 0.8321322553132751\n",
      "-----Test set statistics-----\n",
      "R-squared of the model in the test set is: 0.8249302330916699\n",
      "Mean absolute error of the prediction is: 0.12570372872861824\n",
      "Mean squared error of the prediction is: 0.02919212187135251\n",
      "Root mean squared error of the prediction is: 0.17085702172094805\n",
      "Mean absolute percentage error of the prediction is: 1.0503577667823942\n"
     ]
    }
   ],
   "source": [
    "# We fit an OLS model using sklearn\n",
    "lrm = LinearRegression()\n",
    "lrm.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# We are making predictions here\n",
    "y_preds_train = lrm.predict(X_train)\n",
    "y_preds_test = lrm.predict(X_test)\n",
    "\n",
    "print(\"R-squared of the model in the training set is: {}\".format(lrm.score(X_train, y_train)))\n",
    "print(\"-----Test set statistics-----\")\n",
    "print(\"R-squared of the model in the test set is: {}\".format(lrm.score(X_test, y_test)))\n",
    "print(\"Mean absolute error of the prediction is: {}\".format(mean_absolute_error(y_test, y_preds_test)))\n",
    "print(\"Mean squared error of the prediction is: {}\".format(mse(y_test, y_preds_test)))\n",
    "print(\"Root mean squared error of the prediction is: {}\".format(rmse(y_test, y_preds_test)))\n",
    "print(\"Mean absolute percentage error of the prediction is: {}\".format(np.mean(np.abs((y_test - y_preds_test) / y_test)) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared of the model on the training set is: 0.0\n",
      "-----Test set statistics-----\n",
      "R-squared of the model on the test set is: -0.0013312851260176561\n",
      "Mean absolute error of the prediction is: 0.3178243812258433\n",
      "Mean squared error of the prediction is: 0.1669676348189956\n",
      "Root mean squared error of the prediction is: 0.4086167334055173\n",
      "Mean absolute percentage error of the prediction is: 2.6437648221337366\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Fitting a ridge regression model. Alpha is the regularization\n",
    "# parameter (usually called lambda). As alpha gets larger, parameter\n",
    "# shrinkage grows more pronounced.\n",
    "ridgeregr = Ridge(alpha=10**37) \n",
    "ridgeregr.fit(X_train, y_train)\n",
    "\n",
    "# We are making predictions here\n",
    "y_preds_train = ridgeregr.predict(X_train)\n",
    "y_preds_test = ridgeregr.predict(X_test)\n",
    "\n",
    "print(\"R-squared of the model on the training set is: {}\".format(ridgeregr.score(X_train, y_train)))\n",
    "print(\"-----Test set statistics-----\")\n",
    "print(\"R-squared of the model on the test set is: {}\".format(ridgeregr.score(X_test, y_test)))\n",
    "print(\"Mean absolute error of the prediction is: {}\".format(mean_absolute_error(y_test, y_preds_test)))\n",
    "print(\"Mean squared error of the prediction is: {}\".format(mse(y_test, y_preds_test)))\n",
    "print(\"Root mean squared error of the prediction is: {}\".format(rmse(y_test, y_preds_test)))\n",
    "print(\"Mean absolute percentage error of the prediction is: {}\".format(np.mean(np.abs((y_test - y_preds_test) / y_test)) * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared of the model on the training set is: 0.0\n",
      "-----Test set statistics-----\n",
      "R-squared of the model on the test set is: -0.0013312851260176561\n",
      "Mean absolute error of the prediction is: 0.3178243812258433\n",
      "Mean squared error of the prediction is: 0.1669676348189956\n",
      "Root mean squared error of the prediction is: 0.4086167334055173\n",
      "Mean absolute percentage error of the prediction is: 2.6437648221337366\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lassoregr = Lasso(alpha=10**20.5) \n",
    "lassoregr.fit(X_train, y_train)\n",
    "\n",
    "# We are making predictions here\n",
    "y_preds_train = lassoregr.predict(X_train)\n",
    "y_preds_test = lassoregr.predict(X_test)\n",
    "\n",
    "print(\"R-squared of the model on the training set is: {}\".format(lassoregr.score(X_train, y_train)))\n",
    "print(\"-----Test set statistics-----\")\n",
    "print(\"R-squared of the model on the test set is: {}\".format(lassoregr.score(X_test, y_test)))\n",
    "print(\"Mean absolute error of the prediction is: {}\".format(mean_absolute_error(y_test, y_preds_test)))\n",
    "print(\"Mean squared error of the prediction is: {}\".format(mse(y_test, y_preds_test)))\n",
    "print(\"Root mean squared error of the prediction is: {}\".format(rmse(y_test, y_preds_test)))\n",
    "print(\"Mean absolute percentage error of the prediction is: {}\".format(np.mean(np.abs((y_test - y_preds_test) / y_test)) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ElasticNet Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared of the model on the training set is: 0.0\n",
      "-----Test set statistics-----\n",
      "R-squared of the model on the test set is: -0.0013312851260176561\n",
      "Mean absolute error of the prediction is: 0.3178243812258433\n",
      "Mean squared error of the prediction is: 0.1669676348189956\n",
      "Root mean squared error of the prediction is: 0.4086167334055173\n",
      "Mean absolute percentage error of the prediction is: 2.6437648221337366\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "elasticregr = ElasticNet(alpha=10**21, l1_ratio=0.5) \n",
    "elasticregr.fit(X_train, y_train)\n",
    "\n",
    "# We are making predictions here\n",
    "y_preds_train = elasticregr.predict(X_train)\n",
    "y_preds_test = elasticregr.predict(X_test)\n",
    "\n",
    "print(\"R-squared of the model on the training set is: {}\".format(elasticregr.score(X_train, y_train)))\n",
    "print(\"-----Test set statistics-----\")\n",
    "print(\"R-squared of the model on the test set is: {}\".format(elasticregr.score(X_test, y_test)))\n",
    "print(\"Mean absolute error of the prediction is: {}\".format(mean_absolute_error(y_test, y_preds_test)))\n",
    "print(\"Mean squared error of the prediction is: {}\".format(mse(y_test, y_preds_test)))\n",
    "print(\"Root mean squared error of the prediction is: {}\".format(rmse(y_test, y_preds_test)))\n",
    "print(\"Mean absolute percentage error of the prediction is: {}\".format(np.mean(np.abs((y_test - y_preds_test) / y_test)) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By a very close margin, the OLS regression is still the best model for this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
